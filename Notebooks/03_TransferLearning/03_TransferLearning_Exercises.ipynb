{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "03_TransferLearning_Exercises.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PYOnt_yJkaI",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNCmsEpLJkaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import useful libraries        (note: don't forget to turn on GPU)\n",
        "\n",
        "# tensorflow for network building/training\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Model, Sequential\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Basic operating system (os), numerical, and plotting functionality\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from matplotlib import pylab as plt\n",
        "\n",
        "# scikit-learn data utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import transform\n",
        "\n",
        "# scikit-learn performance metric utilities\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Color transformations\n",
        "from skimage.color import rgb2lab\n",
        "\n",
        "#Skimage resizing \n",
        "from skimage.transform import resize\n",
        "\n",
        "# Garbage collection (for saving RAM during training)\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IkUE60WJkaQ",
        "colab_type": "text"
      },
      "source": [
        "## VGG16 Model\n",
        "\n",
        "For this exercise you'll now use the VGG16 model as the feature extractor. https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16\n",
        "\n",
        "Specifications:\n",
        "- Default input size: 224x224, no smaller than 32x32 pixels\n",
        "- Default output classes: 1000\n",
        "\n",
        "Our images are 150x150 pixels in size and come from only **eight categories**. In order to use this model for our classification task, we again can/need to do the following:\n",
        "* Resize images : Our input images can be resized to the appropriate dimensions. Alternatively, we can pad our images to the expected dimensions. Padding leads to additional choices - Do we pad with zeros, duplicate edge pixels or mirror the image across edges?\n",
        "* Change the prediction layer : Remove the existing prediction layer and add a new layer that can predict **8 classes**.\n",
        "* Train : Finally, we need to train the network on our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teogiXA3Jkak",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwwkYk48Jkal",
        "colab_type": "text"
      },
      "source": [
        "Getting path and changing directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYdSaY2PJkam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the current directory and the directory where the files to download can\n",
        "# be found\n",
        "current_dir = os.getcwd()\n",
        "remote_path = 'https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week3/data_nuclei/crc/'\n",
        "\n",
        "# Define and build a directory to save this data in\n",
        "data_dir = os.path.join(current_dir, 'crc_data')\n",
        "if not os.path.isdir(data_dir):\n",
        "  os.mkdir(data_dir)\n",
        "\n",
        "# Move into the data directory and download all of the files\n",
        "os.chdir(data_dir)\n",
        "for ii in range(1, 6):\n",
        "    basename = f'rgb0{ii}.npz'\n",
        "    filename = os.path.join(remote_path, basename)\n",
        "\n",
        "    # Check if the file has already been downloaded\n",
        "    if not os.path.isfile(basename):\n",
        "      cmd = f'wget {filename}'\n",
        "      print(cmd)\n",
        "      os.system(cmd)\n",
        "\n",
        "# Return to the original directory\n",
        "os.chdir(current_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoYrP7JXJkat",
        "colab_type": "text"
      },
      "source": [
        "Function for loading images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sesRgeVJkau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to load the data from the assumed download path\n",
        "def load_images(colorspace='rgb'):\n",
        "    \"\"\"\n",
        "    Loads the example data and applies transformation into requested colorspace\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    colorspace : str, optional, default: `rgb`\n",
        "        The colorspace into which the images should be transformed. Accepted\n",
        "        values include\n",
        "\n",
        "        'rgb' : Standard red-green-blue color-space for digital images\n",
        "\n",
        "        'gray' or 'grey': An arithmetic average of the (r, g, b) values\n",
        "\n",
        "        'lab': The CIE L*a*b* colorspace\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    images : numpy.ndarray, shape (Nimg, Ny, Nx, Ncolor)\n",
        "        The complete set of transformed images\n",
        "\n",
        "    labels : numpy.ndarray, shape (Nimg)\n",
        "        The classification labels associated with each entry in `images`\n",
        "\n",
        "    label_to_str : dict\n",
        "        A dictionary which converts the numerical classification value in\n",
        "        `labels` into its string equivalent representation.\n",
        "    \"\"\"\n",
        "    # Check that the colorspace argument is recognized\n",
        "    colorspace_lower = colorspace.lower()\n",
        "    if colorspace_lower not in ['rgb', 'gray', 'grey', 'lab']:\n",
        "        raise ValueError(f'`colorspace` value of {colorspace} not recognized')\n",
        "\n",
        "    # Load data, which is stored as a numpy archive file (.npz)\n",
        "    filename = os.path.join(data_dir, 'rgb01.npz')\n",
        "    print(f'loading {filename}')\n",
        "    tmp = np.load(os.path.join(data_dir, 'rgb01.npz'), allow_pickle=True)\n",
        "\n",
        "    # Parse the loaded data into images and labels\n",
        "    # Initialize the images and labels variables using the first archive data\n",
        "    images = tmp['rgb_data']\n",
        "    if colorspace_lower == 'rgb':\n",
        "        pass\n",
        "    elif colorspace_lower in ['gray', 'grey']:\n",
        "        images = np.mean(images, axis=-1)      # Average into grayscale\n",
        "    elif colorspace_lower == 'lab':\n",
        "        images = rgb2lab(images)               # Convert to CIE L*a*b*\n",
        "\n",
        "    # Grab the initial array for the image labels\n",
        "    labels = tmp['labels']\n",
        "    \n",
        "    # Grab the dictionary to convert numerical labels to their string equivalent\n",
        "    label_to_str = tmp['label_str']\n",
        "    label_to_str = label_to_str.tolist() # Convert label_to_str into a dict\n",
        "\n",
        "    # Update the user on the number and size of images loaded\n",
        "    print('Loaded images with shape {}'.format(images.shape))\n",
        "    del tmp\n",
        "\n",
        "    # Loop over each of the remaining archives and append the contained data\n",
        "    for ii in range(2,6):\n",
        "        # Build the full path to the archive and load it into memory\n",
        "        filename = os.path.join(data_dir, f'rgb0{ii}.npz')\n",
        "        print(f'loading {filename}')\n",
        "        tmp = np.load(filename, allow_pickle=True)\n",
        "\n",
        "        # Parse and append the data\n",
        "        these_images = tmp['rgb_data']\n",
        "        if colorspace_lower == 'rgb':\n",
        "            pass\n",
        "        elif (colorspace_lower == 'gray') or (colorspace_lower == 'grey'):\n",
        "            these_images = np.mean(these_images, axis=-1) # Convert to grayscale\n",
        "        elif colorspace_lower == 'lab':\n",
        "            these_images = rgb2lab(these_images)          # Convert to CIEL*a*b*\n",
        "\n",
        "        # Append the images and labels\n",
        "        images = np.append(images, these_images, axis=0)\n",
        "        labels = np.append(labels, tmp['labels'], axis=0)\n",
        "\n",
        "        # Update the user on the number and size of images\n",
        "        print('Loaded images with shape {}'.format(these_images.shape))\n",
        "        del tmp\n",
        "\n",
        "    # Force the image data to be floating point and print the data shape\n",
        "    images = images.astype(np.float)\n",
        "    print('Final image data shape: {}'.format(images.shape))\n",
        "    print('Number of image labels: {}'.format(*labels.shape))\n",
        "\n",
        "    return images, labels, label_to_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gg4B0EOJka1",
        "colab_type": "text"
      },
      "source": [
        "Load images and labels into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXzdtPccJka3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_full_res, labels, label_to_str = load_images()\n",
        "num_classes = np.unique(labels).size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ri4n4KK3Ql",
        "colab_type": "text"
      },
      "source": [
        "## Pre-process the Images\n",
        "\n",
        "***Note: you'll have to edit a line of code in the cell for resizing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZqvdtsqJka7",
        "colab_type": "text"
      },
      "source": [
        "Resizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gAiiGUSJka7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This boolean can be switched to false if you do not want to resize the images\n",
        "resize_images_bool = True\n",
        "\n",
        "# Specify a new shape to use for the resized images\n",
        "# NOTE: For the VGG16 model, we must use a size of at least (32, 32).\n",
        "original_shape = images_full_res.shape\n",
        "new_shape = list(original_shape)\n",
        "new_shape[1:3] = ## YOUR CODE HERE\n",
        "\n",
        "# Compute if we are downsampling (in which case we need anti-aliasing)\n",
        "scaling_ratio = np.array(new_shape[1:3])/np.array(original_shape[1:3])\n",
        "anti_alias = np.any(scaling_ratio < 1)\n",
        "\n",
        "# If resizing is requested, then run the resizing transformation\n",
        "if resize_images_bool:\n",
        "    # Grab the original shape of the images\n",
        "    num_images = images_full_res.shape[0]\n",
        "\n",
        "    # Initialize an array for storing the resized images\n",
        "    images = np.zeros(new_shape, dtype=np.float16)\n",
        "\n",
        "    # Loop over each image in the data and perform a resizing operation\n",
        "    for img_num, img_data in enumerate(images_full_res):\n",
        "        # Update the user on progress\n",
        "        if np.mod(img_num, 1000) == 0:\n",
        "            print(f'Processing image number {img_num}')\n",
        "\n",
        "        # Process the image and force it to be a 16-bit float\n",
        "        processed_img = transform.resize(img_data, new_shape[1:],\n",
        "                                         anti_aliasing=anti_alias)\n",
        "        images[img_num] = processed_img.astype(np.float16)\n",
        "\n",
        "# If no resizing requested, then just rename that data\n",
        "else:\n",
        "    images = images_full_res\n",
        "\n",
        "# Remove the full-resolution versions from memory (just clogging things up)\n",
        "del images_full_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQjuP1H1JkbE",
        "colab_type": "text"
      },
      "source": [
        "Normalize the images (if it hasn't been done already)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE3wO4fKJkbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note, we cast image data as float16 to save RAM\n",
        "images = images.astype(np.float16)/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA8WJ25FTKjS",
        "colab_type": "text"
      },
      "source": [
        "Include an axis for color channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNYIGee0TNK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take note of number of color channels in the loaded image add a last axis to \n",
        "# images ndarray if array dimension is only 3 (as is the case with grayscale images)\n",
        "if images.ndim == 3:\n",
        "    # If image is grayscale, then we add a last axis (of len 1) for channel\n",
        "    n_channels = 1\n",
        "    images = images[:, : , :, np.newaxis]\n",
        "    print('\\nlast dimension added to images ndarray to account for channel')\n",
        "    print(f'new images.shape: {images.shape}')\n",
        "else:\n",
        "    #if image is not grayscale, last dimension of image already corresponds to channel\n",
        "    n_channels = images.shape[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHV6NK27JkbA",
        "colab_type": "text"
      },
      "source": [
        "Split data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwmn7EuuJkbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into train and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=.2)\n",
        "\n",
        "# Convert 'labels' (1D array of integers) to one-hot encoding\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "# Print sizes of train/test sets\n",
        "print(f'train_images.shape: {train_images.shape}')\n",
        "print(f'train_labels.shape: {train_labels.shape}')\n",
        "print(f'test_images.shape: {test_images.shape}')\n",
        "print(f'test_labels.shape: {test_labels.shape}')\n",
        "\n",
        "# Print the one-hot encoded labels as a sanity check\n",
        "print('one-hot encoded labels:')\n",
        "print(train_labels)\n",
        "\n",
        "# Get rid of the duplicate copies of the data\n",
        "del images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D9uhLlSJkbM",
        "colab_type": "text"
      },
      "source": [
        "## Load Pre-trained VGG16 Model\n",
        "\n",
        "here's the link to documentation again (https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16), also reference the tutorial notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om5GOu21JkbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the base pre-trained model\n",
        "print('loading VGG16')\n",
        "base_model = ## YOUR CODE HERE\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhA1SR6VJkbR",
        "colab_type": "text"
      },
      "source": [
        "Summarize model structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sQGrHQjJkbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYNFl2ZOJkbZ",
        "colab_type": "text"
      },
      "source": [
        "Freezing layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLC3uT3cJkba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Play around with freezing layers, take a look at the tutorial notebook for reference \n",
        "\n",
        "# By default we'll just freeze the entire base model again\n",
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjn-7TTxJkbV",
        "colab_type": "text"
      },
      "source": [
        "Modify the pre-trained network by adding a few new layers at the output, including a classification layer (remember we want to predict 8 different classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-skRWsOAJkbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add a global spatial average pooling layer\n",
        "## YOUR CODE HERE\n",
        "\n",
        "# Add a fully-connected layer\n",
        "## YOUR CODE HERE\n",
        "\n",
        "# Add the final classification layer\n",
        "## YOUR CODE HERE\n",
        "\n",
        "# Build the model you will train\n",
        "model = ## YOUR CODE HERE\n",
        "\n",
        "# Print summary of model layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvwvRkiVJkbd",
        "colab_type": "text"
      },
      "source": [
        "Compiling model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC-_ZFi_Jkbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model (should be done *after* setting layers to non-trainable)\n",
        "    # optimizer: rmsprop\n",
        "    # loss: categorical crossentropy\n",
        "    # metrics: accuracy\n",
        "  \n",
        "## YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29DxiSHbJkbh",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsYo9vGeeMBM",
        "colab_type": "text"
      },
      "source": [
        "Train the model on the new, histological, data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXtYUBTOeWl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our training and validation ('test') data to TensorFlow data\n",
        "# This prevents the training algorithm from needing to make a *copy* of your\n",
        "# numpy arrays, which would EAT UP SOO MUCH RAM!\n",
        "#\n",
        "# It also accelerates training a bit because there is no data-conversion step\n",
        "train_images_tf = tf.constant(train_images, dtype=tf.float16)\n",
        "test_images_tf = tf.constant(test_images)\n",
        "del train_images, test_images\n",
        "\n",
        "train_labels_tf = tf.constant(train_labels, dtype=tf.float16)\n",
        "test_labels_tf = tf.constant(test_labels)\n",
        "del train_labels, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J-uBwdWerN5",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpKK3afvJkbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function is called after each epoch\n",
        "# (It will ensure that your training process does not consume all available RAM)\n",
        "class garbage_collect_callback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    gc.collect()\n",
        "\n",
        "# Time how long it takes the model to train for these epochs\n",
        "start_time = time.time()\n",
        "\n",
        "# Perform the training method\n",
        "history = model.fit(train_images_tf,\n",
        "                    train_labels_tf,\n",
        "                    batch_size=64,\n",
        "                    epochs= 50,\n",
        "                    verbose=1,\n",
        "                    validation_data=(test_images_tf, test_labels_tf),\n",
        "                    callbacks = [garbage_collect_callback()])\n",
        "\n",
        "stop_time = time.time()\n",
        "print(\"--- %s seconds ---\" % (stop_time - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPGyseHcJkbk",
        "colab_type": "text"
      },
      "source": [
        "Plot model train/validation accuracy and model train/validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXegpORpJkbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8GR-I4mJkbp",
        "colab_type": "text"
      },
      "source": [
        "## Make Predictions for Test Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QucAFGw1Jkbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict class of test each test\n",
        "predictions = model.predict(test_images_tf, verbose=True)\n",
        "\n",
        "# Convert the predictions and true labels into category numbers\n",
        "test_true_labels = test_labels_tf.numpy().argmax(axis=1)\n",
        "test_pred_labels = predictions.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHx3kt6GJkbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot a set of test images, along with predicted labels and true labels\n",
        "plt.figure(figsize=(16,20))\n",
        "for ii in range(0, 16):\n",
        "    # Activate subplot and display image\n",
        "    plt.subplot(4,4,ii+1)\n",
        "    plt.imshow(test_images_tf[ii+100,:,:,:].numpy().astype(np.float))\n",
        "\n",
        "    # Turn off axes\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Add annotaiton\n",
        "    plt.title('expected : ' + label_to_str[test_true_labels[ii+100]]\n",
        "              + '\\npredicted : ' + label_to_str[test_pred_labels[ii+100]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntDR6ZWYiEgN",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRrEEXx9iGZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = accuracy_score(test_true_labels, test_pred_labels)\n",
        "print(f'Model Accuracy: {acc:.2%}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpj8PtZuiIAU",
        "colab_type": "text"
      },
      "source": [
        "Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp7rdgkciJJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf_mat = confusion_matrix(test_true_labels, test_pred_labels)\n",
        "\n",
        "# Generate a new figure\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# Display the confusion matrix\n",
        "plt.imshow(conf_mat, cmap='hot', interpolation='nearest')\n",
        "\n",
        "# Add some anotation for the plot\n",
        "plt.colorbar()\n",
        "plt.xlabel('True label')\n",
        "plt.ylabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFwpTudBiMdv",
        "colab_type": "text"
      },
      "source": [
        "### To-do:\n",
        "\n",
        "Continue playing around with preprocessing (image size) and the model (added layers, freezing layers, optimizer, # epochs) and see their effects on the accuracy. Doing this may help you for the challenge problem :O"
      ]
    }
  ]
}